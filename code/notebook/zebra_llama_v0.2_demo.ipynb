{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba255f90-f7db-4eb5-b53f-2edbeaaa0901",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from transformers import TextStreamer\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "import os\n",
    "import requests\n",
    "import torch\n",
    "from transformers import TextIteratorStreamer, StoppingCriteria, StoppingCriteriaList\n",
    "import re\n",
    "from collections import Counter\n",
    "from threading import Thread\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf7878d-b08b-4356-b3b1-ab6f650927eb",
   "metadata": {},
   "source": [
    "## Load Zebra-Llama from Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ebe43-a346-4c28-a64e-82af3d57d0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"zebraLLAMA/zebra-Llama-v0.2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"zebraLLAMA/zebra-Llama-v0.2\")\n",
    "\n",
    "device = next(model.parameters()).device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8a7152-51c2-44fb-8db1-ab6207185192",
   "metadata": {},
   "source": [
    "## Set RAG parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a57f9c-e660-4e20-b87b-be9ae946f88c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAG_BASE_URI = \"https://zebra-llama-rag.onrender.com\"\n",
    "RAG_ENDPOINT = \"/search\"\n",
    "RAG_URI = RAG_BASE_URI + RAG_ENDPOINT\n",
    "TOP_K = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea28a25b-dc9c-4e3a-9005-57167f04333f",
   "metadata": {},
   "source": [
    "## Set Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9023850-c4c2-48e9-949f-1bd80d5f1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Replace the env file and key names based on the configuration you provided\n",
    "\n",
    "load_dotenv(os.path.join(os.path.expanduser('~'), '.openai_config.env'))\n",
    "embed_model = OpenAIEmbedding(\n",
    "    model=config_data['RAG_EMBEDDING_MODEL'],\n",
    "    api_key=os.environ.get('HACKATHON_API_KEY'),\n",
    ")\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993e9468-219e-4add-940c-d57673a8d2ce",
   "metadata": {},
   "source": [
    "## Set System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4909ac-efad-47ce-838a-9cec50f51022",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = '''\n",
    "You are an expert AI assistant specializing in Ehlers-Danlos syndrome (EDS). Your role is to provide comprehensive, accurate, and well-structured answers about EDS. You will be provided with a prompt that has two components such as \"User message\" and \"Context\". Follow these guidelines to address the prompt:\n",
    "\n",
    "- In the first paragraph, begin with a broad overview that directly addresses the \"User message\".\n",
    "- In the second paragraph, provide detailed information mainly by using the given \"Context\". Also use your trained knowledge about EDS to supplement the assertions. If you don't see relevant information in the context, always mention that in your response and stick on to your own internal knowledge to answer the question.\n",
    "- Answer in multiple paragraphs and be comprehensive in your answer\n",
    "- Structure your response logically:\n",
    "     a) Start with a general answer to the question.\n",
    "     b) Provide specific examples or details, always with proper citations. \n",
    "     c) You can find the citations at the end of each \"Context\" para marked as '(Ref: '. Do not use any references that do not contain a DOI, and do not use references that contain just numbers in square brackets. Here are examples of references to avoid: [ 1 ], [5, 6, 8], etc.\n",
    "- If mentioning specific studies or cases, clearly state their relevance to the main question and provide proper context. \n",
    "- When answering questions based on provided context, do not use phrases like 'The context provided' or 'In the provided context' in your responses.\n",
    "- In the last paragraph, conclude with a brief summary of the key points.\n",
    "IMPORTANT: If you receive a question unrelated to Ehlers-Danlos Syndrome (EDS), respond directly by stating that the question is not related, without providing any additional context or explanations. For example, if the question is \"Who is the actor in the movie titanic\" and even if it has any EDS context given in the \"Context\", your answer should be like \"Sorry, this question is not related to EDS and I cannot address that.\"\n",
    "\n",
    "Some examples for your reference are given below:\n",
    "Example 1:\n",
    "Context : Context not related to EDS\n",
    "User message: What is the most popular song of Taylor Swift?\n",
    "Your response : Sorry, this question is not directly related to EDS. So, I cannot answer that.\n",
    "\n",
    "Example 2:\n",
    "Context : The analysis of the hEDS patients’ ﬁbroblasts showed that there is a greater expression\n",
    "of AQP9 gene and down regulation of IL6 gene. AQP9 and IL6 are involved in the\n",
    "inﬂammatory process, since EDS patients frequently show chronic disease, AQP9 and IL6\n",
    "could be use as possible diagnostic biomarkers.\n",
    "In addition, PRL may have a role in inﬂammation and their serum levels could suggest\n",
    "a clinical situation of chronic inﬂammation that is frequent in EDS patients. Scientiﬁc data\n",
    "show the up-regulation of SELENBP1 in schizophrenic patients. Considering that EDS\n",
    "patients suffer from psychiatric disorders, it would be interesting to dose SELENBP1 in\n",
    "serum EDS patients.\n",
    "User message: What are the biomarkers associated with EDS?\n",
    "Your response: Biomarkers are measurable indicators that can be used to assess the presence or severity of a disease. For Ehlers-Danlos Syndrome (EDS), research has identified several potential biomarkers that could help in diagnosing or understanding the disease better. EDS is a group of connective tissue disorders characterized by hypermobility, skin elasticity, and tissue fragility. Identifying reliable biomarkers is crucial for effective diagnosis and management, given the complex and varied symptoms associated with different types of EDS.\n",
    "One of the potential biomarkers in EDS is the **Aquaporin 9 (AQP9) gene**, which has been shown to be overexpressed in the fibroblasts of hypermobile EDS (hEDS) patients. AQP9 plays a role in the inflammatory process, and its increased expression may be linked to the chronic inflammation often observed in EDS patients. Additionally, the **Interleukin-6 (IL6) gene**, which is also involved in inflammation, has been found to be downregulated in these patients. This dysregulation of genes related to the inflammatory response suggests that both AQP9 and IL6 could serve as useful diagnostic markers in identifying inflammatory states associated with EDS.\n",
    "Furthermore, **Prolactin (PRL)** has been suggested as another potential biomarker. Elevated serum levels of PRL may indicate a state of chronic inflammation, which is frequently observed in EDS patients. Another interesting biomarker is **SELENBP1** (selenium-binding protein 1), which is known to be upregulated in patients with schizophrenia. Considering the higher prevalence of psychiatric disorders in EDS patients, the measurement of SELENBP1 levels could be relevant in the context of EDS-related psychiatric manifestations. These findings, while still in the early stages of research, could pave the way for better diagnostic tools and therapeutic targets for EDS (Ref: 10.3390/ijms221810149).\n",
    "In summary, biomarkers such as AQP9, IL6, PRL, and SELENBP1 are being explored in the context of EDS to help clarify the underlying mechanisms of the disease and potentially improve diagnostic accuracy. Further research and validation are necessary to establish these markers as definitive diagnostic tools.\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559814a6-2846-4a04-aae0-7b30f32b2dcb",
   "metadata": {},
   "source": [
    "## Custom Functions and Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1f6352-7d31-4423-bab2-53e54e9de169",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rag_context(query, rag_uri, top_k=2):\n",
    "    query_embedding = embed_model.get_text_embedding(query)\n",
    "    response = requests.post(\n",
    "        rag_uri,\n",
    "        json={\n",
    "            \"query_embedding\": query_embedding,\n",
    "            \"top_k\": top_k\n",
    "        }\n",
    "    )\n",
    "    if response.status_code == 200:\n",
    "        return response.json()[\"context\"]\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "class RepetitionStoppingCriteria(StoppingCriteria):\n",
    "    def __init__(self, tokenizer, repetition_threshold=3, window_size=200, min_length=20):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.repetition_threshold = repetition_threshold\n",
    "        self.window_size = window_size\n",
    "        self.min_length = min_length\n",
    "        self.generated_text = \"\"\n",
    "        self.last_check_length = 0\n",
    "\n",
    "    def __call__(self, input_ids, scores, **kwargs):\n",
    "        new_text = self.tokenizer.decode(input_ids[0, self.last_check_length:], skip_special_tokens=True)\n",
    "        self.generated_text += new_text\n",
    "        self.last_check_length = len(input_ids[0])\n",
    "\n",
    "        if len(self.generated_text) > self.window_size and self.check_repetition():\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def check_repetition(self):\n",
    "        text = self.generated_text[-self.window_size:]\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        \n",
    "        # Check for exact sentence repetitions\n",
    "        sentence_counter = Counter(sentences)\n",
    "        if any(count >= self.repetition_threshold for count in sentence_counter.values()):\n",
    "            return True\n",
    "\n",
    "        # Check for phrase repetitions\n",
    "        phrases = self.get_phrases(text)\n",
    "        phrase_counter = Counter(phrases)\n",
    "        if any(count >= self.repetition_threshold and len(phrase) >= self.min_length for phrase, count in phrase_counter.items()):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def get_phrases(self, text):\n",
    "        words = text.split()\n",
    "        phrases = []\n",
    "        for i in range(len(words)):\n",
    "            for j in range(i+1, len(words)+1):\n",
    "                phrase = ' '.join(words[i:j])\n",
    "                if len(phrase) >= self.min_length:\n",
    "                    phrases.append(phrase)\n",
    "        return phrases\n",
    "\n",
    "    \n",
    "def generate_text_using_stream(query, model, return_out=True):\n",
    "    \n",
    "    rag_context = get_rag_context(query, RAG_URI, top_k=TOP_K)\n",
    "    prompt = f'''\n",
    "    Context: {rag_context}\n",
    "    User message: {query}\n",
    "    '''\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    model_input = tokenizer(text, \n",
    "                            padding=True, \n",
    "                            return_tensors=\"pt\").to(device)\n",
    "    \n",
    "    generation_kwargs = dict(\n",
    "        **model_input,\n",
    "        max_new_tokens=1024,\n",
    "        top_p=0.95,\n",
    "        top_k=50,\n",
    "        do_sample=True,\n",
    "        streamer=streamer,\n",
    "        stopping_criteria=StoppingCriteriaList([stopping_criteria])\n",
    "    )\n",
    "    \n",
    "    # Start the generation in a separate thread\n",
    "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
    "    thread.start()\n",
    "    \n",
    "    # Iterate over the generated text\n",
    "    generated_text = \"\"\n",
    "    for new_text in streamer:\n",
    "        generated_text += new_text\n",
    "        print(new_text, end=\"\", flush=True)  # Print each piece of new text as it's generated\n",
    "    \n",
    "    thread.join()\n",
    "    clear_output()\n",
    "    if return_out:\n",
    "        return generated_text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef241d71-d4ac-4f8c-82bd-f6ca7124635a",
   "metadata": {},
   "source": [
    "## User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b0f45b-f8d0-436d-a014-004c94a7b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "query = \"What are the genetic markers of EDS?\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7fa0bdc-f85a-4673-84b1-5f3a74fe44ac",
   "metadata": {},
   "source": [
    "## Generate Response from Zebra-Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0107e81-744a-40d2-b321-583df9765070",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resp = generate_text_using_stream(query, model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
