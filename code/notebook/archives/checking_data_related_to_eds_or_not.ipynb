{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e6224e2-102b-4209-89c6-a5ebd9d6fca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "from utility import REPO_ROOT_PATH, get_GPT_response, client\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "import numpy as np\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e24a06f-9214-4bea-9ba5-fe090fd12932",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eds_check(text):\n",
    "    system_prompt = '''You are an expert in Ehlers-Danlos syndrome (EDS). \n",
    "    Given the user message, you analyse it and see if it is related to EDS or not.\n",
    "    If it is related to EDS, return True, else return False. \n",
    "    Do not return any other explanation, only return the boolean.\n",
    "    '''\n",
    "    response = get_GPT_response(text, system_prompt, os.environ.get('MODEL_NAME'), temperature=0.3)\n",
    "    return response\n",
    "\n",
    "\n",
    "def batch_eds_check(text_batch):\n",
    "    system_prompt = '''You are an expert in Ehlers-Danlos syndrome (EDS).\n",
    "    Given the array of user messages, you analyse every element of the array and see if each element of the array is related to EDS or not.\n",
    "    If it is related to EDS, return True, else return False. \n",
    "    Do not return any other explanation, only return a list of booleans.\n",
    "    For example:\n",
    "    if the input is [\"what are the symptoms of EDS\", \"what is the capital of france\"]\n",
    "    your response should be an array as follows:\n",
    "    ['True', 'False']\n",
    "    '''    \n",
    "    promptsArray = text_batch    \n",
    "    stringifiedPromptsArray = json.dumps(promptsArray)        \n",
    "    prompts = [\n",
    "        {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": stringifiedPromptsArray\n",
    "    }\n",
    "    ]\n",
    "    \n",
    "    batchInstruction = {\n",
    "        \"role\":\"system\",\n",
    "        \"content\":system_prompt\n",
    "    }\n",
    "    \n",
    "    prompts.append(batchInstruction)\n",
    "    \n",
    "    stringifiedBatchCompletion = client.chat.completions.create(model=os.environ.get('MODEL_NAME'),\n",
    "                                             messages=prompts,\n",
    "                                             max_tokens=1000)\n",
    "    try:\n",
    "        batchCompletion = ast.literal_eval(stringifiedBatchCompletion.choices[0].message.content)\n",
    "        return batchCompletion\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4148c941-d13e-4f75-9011-c6ce6aaf8692",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join(REPO_ROOT_PATH, 'eds_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21424d10-5355-4595-8e6b-f60df3f8a606",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data_path = 'reddit_data/reddit_data_2'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3058166-88e6-41df-ac91-0306ccc50ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(os.path.join(DATA_PATH, reddit_data_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f812f125-9ae3-45a3-bfc1-c4b66ad40d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sel_data = []\n",
    "for index, file in enumerate(files):\n",
    "    with open(os.path.join(DATA_PATH, reddit_data_path, file), 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for data_ in data:\n",
    "            sel_data.append(data_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5560cb5d-9f53-4607-8932-9f916393fe00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 165/165 [09:06<00:00,  3.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.2 s, sys: 257 ms, total: 4.46 s\n",
      "Wall time: 9min 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "batch_size = 50\n",
    "nbatch = math.ceil(len(sel_data)/batch_size)\n",
    "sel_data_batch = np.array_split(sel_data, nbatch)\n",
    "\n",
    "verified_data = []\n",
    "for data_batch in tqdm(sel_data_batch):\n",
    "    data_batch_text = list(map(lambda x:x['instruction'], data_batch))\n",
    "    response = batch_eds_check(data_batch_text)\n",
    "    if response:\n",
    "        try:\n",
    "            data_batch_text_sel = np.array(data_batch_text)[np.where(np.array(response) == 'True')[0]]\n",
    "            verified_data.extend(data_batch_text_sel)\n",
    "        except:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fc303cdc-5692-4ffc-b19a-f6e039e93285",
   "metadata": {},
   "outputs": [],
   "source": [
    "verified_data_json = []\n",
    "for item in sel_data:\n",
    "    if item['instruction'] in verified_data:\n",
    "        verified_data_json.append(item)\n",
    "            \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f4fa9acf-e9e3-4872-8739-1b41cb520864",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_PATH, reddit_data_path, 'verified_data', 'reddit_data_2_verified.json'), 'w') as f:\n",
    "    json.dump(verified_data_json, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da913772-52fb-4e0c-bcfa-13866265beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# batch_size = 100\n",
    "# nbatch = math.ceil(len(sel_data)/batch_size)\n",
    "# sel_data_batch = np.array_split(sel_data, nbatch)\n",
    "\n",
    "# verified_data = []\n",
    "# for index, data_batch in tqdm(enumerate(sel_data_batch)):\n",
    "#     data_batch_text = list(map(lambda x:x['instruction'], data_batch))\n",
    "#     response = batch_eds_check(data_batch_text)\n",
    "#     if response:\n",
    "#         try:\n",
    "#             data_batch_text_sel = np.array(data_batch_text)[np.where(np.array(response) == 'True')[0]]\n",
    "#             verified_data.extend(data_batch_text_sel)\n",
    "#         except:\n",
    "#             for item in data_batch_text:\n",
    "#                 response = eds_check(item)\n",
    "#                 if response == 'True':\n",
    "#                     verified_data.extend([item])\n",
    "#     else:\n",
    "#         for item in data_batch_text:\n",
    "#             response = eds_check(item)\n",
    "#             if response == 'True':\n",
    "#                 verified_data.extend([item])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3f19437-d79e-4fe9-918f-179b045ddb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# import ast\n",
    "\n",
    "# system_prompt = '''You are an expert in Ehlers-Danlos syndrome (EDS).\n",
    "# Given the array of user messages, you analyse every element of the array and see if each element of the array is related to EDS or not.\n",
    "# If it is related to EDS, return True, else return False. \n",
    "# Do not return any other explanation, only return an array of booleans.\n",
    "# For example:\n",
    "# if the input is ['what are the symptoms of EDS', 'what is the capital of france']\n",
    "# your response should be:\n",
    "# ['True', 'False']\n",
    "# '''\n",
    "\n",
    "# promptsArray = sel_data\n",
    "\n",
    "# stringifiedPromptsArray = json.dumps(promptsArray)\n",
    "\n",
    "# # print(promptsArray)\n",
    "\n",
    "# prompts = [\n",
    "#     {\n",
    "#     \"role\": \"user\",\n",
    "#     \"content\": stringifiedPromptsArray\n",
    "# }\n",
    "# ]\n",
    "\n",
    "# batchInstruction = {\n",
    "#     \"role\":\"system\",\n",
    "#     \"content\":system_prompt\n",
    "# }\n",
    "\n",
    "# prompts.append(batchInstruction)\n",
    "\n",
    "# print(\"ChatGPT: \")\n",
    "# stringifiedBatchCompletion = client.chat.completions.create(model=os.environ.get('MODEL_NAME'),\n",
    "#                                          messages=prompts,\n",
    "#                                          max_tokens=1000)\n",
    "# batchCompletion = ast.literal_eval(stringifiedBatchCompletion.choices[0].message.content)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9938e981-1a87-417a-b4e7-ff9fd3a295f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# system_prompt = 'you are a helpful assistant'\n",
    "\n",
    "\n",
    "# promptsArray = [\"Hello world, from\", \"How are you B\", \"I am fine. W\", \"The  fifth planet from the Sun is \"]\n",
    "\n",
    "# stringifiedPromptsArray = json.dumps(promptsArray)\n",
    "\n",
    "# print(promptsArray)\n",
    "\n",
    "# prompts = [\n",
    "#     {\n",
    "#     \"role\": \"user\",\n",
    "#     \"content\": stringifiedPromptsArray\n",
    "# }\n",
    "# ]\n",
    "\n",
    "# batchInstruction = {\n",
    "#     \"role\":\"system\",\n",
    "#     \"content\":\"Complete every element of the array. Reply with an array of all completions.\"\n",
    "# }\n",
    "\n",
    "# prompts.append(batchInstruction)\n",
    "\n",
    "# print(\"ChatGPT: \")\n",
    "# stringifiedBatchCompletion = client.chat.completions.create(model=os.environ.get('MODEL_NAME'),\n",
    "#                                          messages=prompts,\n",
    "#                                          max_tokens=1000)\n",
    "# batchCompletion = json.loads(stringifiedBatchCompletion.choices[0].message.content)\n",
    "# print(batchCompletion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4201f4eb-416c-4829-bd8c-ff85c34dce6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
