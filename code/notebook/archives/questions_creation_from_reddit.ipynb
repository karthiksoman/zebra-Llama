{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.tools.reddit_search.tool import RedditSearchRun\n",
    "from langchain_community.utilities.reddit_search import RedditSearchAPIWrapper\n",
    "from langchain_community.tools.reddit_search.tool import RedditSearchSchema\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "dotenv_path = os.path.join('/Users/mariacatalinavilloutareyes/dev', '.eds.env')\n",
    "load_dotenv(dotenv_path)\n",
    "client_id = os.environ.get('client_id')\n",
    "client_secret = os.environ.get('client_secret')\n",
    "user_agent = os.environ.get('user_agent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')\n",
    "model = ChatOpenAI(openai_api_key=OPENAI_API_KEY, model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Reddit Search API wrapper\n",
    "search = RedditSearchRun(\n",
    "    api_wrapper=RedditSearchAPIWrapper(\n",
    "        reddit_client_id=client_id,\n",
    "        reddit_client_secret=client_secret,\n",
    "        reddit_user_agent=user_agent,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_reddit(query, sort_by=\"relevance\", time_filter=\"all\", subreddit=\"EhlersDanlos+ChronicPain+Hypermobility\", limit=10000):\n",
    "    \"\"\"\n",
    "    Search Reddit for a given query.\n",
    "    Args:\n",
    "        query (str): The search query to use.\n",
    "        sort_by (str, optional): The sorting method for the search results. Accepted values are \"relevance\", \"hot\", \"top\", \"new\", and \"comments\".\n",
    "        time_filter (str, optional): The time filter for the search results. Accepted values are \"all\", \"year\", \"month\", \"week\", \"day\", and \"hour\".\n",
    "        subreddit (str, optional): The subreddit to search in.\n",
    "        limit (int, optional): The maximum number of search results to return.\n",
    "    Returns:\n",
    "        list: A list of dictionaries containing the search results from Reddit.\n",
    "    \"\"\"\n",
    "    search_params = RedditSearchSchema(\n",
    "        query=query,\n",
    "        sort=sort_by,\n",
    "        time_filter=time_filter,\n",
    "        subreddit=subreddit,\n",
    "        limit=limit\n",
    "    )\n",
    "    result = search.run(tool_input=search_params.dict())\n",
    "    \n",
    "    posts = []\n",
    "    if isinstance(result, str):\n",
    "        result_lines = result.split(\"\\n\\nPost Title: '\")\n",
    "        for i, post_str in enumerate(result_lines):\n",
    "            if i == 0:\n",
    "                post_str = post_str.split(\"Post Title: '\", 1)[-1]\n",
    "            lines = post_str.strip().split(\"\\n\")\n",
    "            post = {}\n",
    "            if lines:\n",
    "                post[\"Post Title\"] = lines[0].strip(\"'\")\n",
    "            text_body = []\n",
    "            for line in lines[1:]:\n",
    "                line = line.strip()\n",
    "                if \": \" in line:\n",
    "                    key, value = line.split(\": \", 1)\n",
    "                    if key.strip() == \"Text body\":\n",
    "                        text_body.append(value.strip())\n",
    "                    else:\n",
    "                        post[key.strip()] = value.strip()\n",
    "                else:\n",
    "                    text_body.append(line.strip())\n",
    "            post[\"Text body\"] = \" \".join(text_body).strip()\n",
    "            posts.append(post)\n",
    "            \n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_output(detailed_output):\n",
    "    \"\"\"\n",
    "    Generate a concise summary of a detailed output.\n",
    "    Args:\n",
    "        detailed_output (str): The detailed output text to summarize.\n",
    "    Returns:\n",
    "        str: A concise summary of the detailed output.\n",
    "    \"\"\"\n",
    "    summary_prompt = f\"\"\"\n",
    "    Summarize the following detailed answer into a concise statement:\n",
    "    {detailed_output}\n",
    "    \"\"\"\n",
    "    summary = model.invoke(summary_prompt).content.strip()\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_question_answer(post, previous_question=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a question and answer based on a given Reddit post about Ehlers-Danlos Syndrome (EDS).\n",
    "\n",
    "    Args:\n",
    "        post (dict): A dictionary containing information about a Reddit post, including the post's text body.\n",
    "        previous_question (str, optional): The previously generated question, if available. Used to ensure that the new question is different from the previous one.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the generated question and answer, with keys \"input\", \"instruction\", and \"output\".\n",
    "              - \"input\" is an empty string.\n",
    "              - \"instruction\" contains the generated question.\n",
    "              - \"output\" contains the generated answer.\n",
    "\n",
    "    The function generates a question that explores the experiences, challenges, or insights related to living with EDS, based on the given Reddit post.\n",
    "    The question is phrased in a general manner, avoiding the use of \"you\" or references to specific individuals, and instead uses inclusive language that applies to the EDS community as a whole.\n",
    "    If a previous question is provided, the function ensures that the new question is different from the previous one while still following the same guidelines.\n",
    "    The function then generates an answer to the question, using the information from the Reddit post, and formats it as a single, coherent paragraph.\n",
    "    \"\"\"\n",
    "    \n",
    "    text_body = post[\"Text body\"]\n",
    "\n",
    "    question_prompt = f\"\"\"\n",
    "    Based on the following Reddit post about Ehlers-Danlos Syndrome (EDS), please generate a question that explores the experiences, challenges, or insights related to living with EDS. The question should be broad and applicable to the EDS community as a whole, rather than directed at any specific individual. Focus on the general themes or topics discussed in the post.\n",
    "\n",
    "    Please ensure that the question is phrased in a general manner without using \"you\" or referring to specific individuals. Instead, use inclusive language that applies to people with EDS collectively, such as \"individuals with EDS,\" \"those living with EDS,\" or \"the EDS community.\"\n",
    "\n",
    "    Do not start the question with phrases like \"General question:\" or \"Question:\". Simply provide the question itself.\n",
    "    \n",
    "    Please use standard characters only, without any special formatting or encoded characters like slashes or escaped quotes. \n",
    "\n",
    "\n",
    "    Reddit post:\n",
    "    {text_body}\n",
    "    \"\"\"\n",
    "    \n",
    "    if previous_question:\n",
    "        question_prompt += f\"\"\"\n",
    "        \\n\\nPreviously generated question: {previous_question}\n",
    "        \n",
    "        Please generate a question that is different from the previous one, while still following the guidelines and formatting mentioned above. Ensure that the new question does not use \"you\" or refer to specific individuals, and instead uses inclusive language that applies to the EDS community as a whole.\n",
    "        \"\"\"\n",
    "    \n",
    "    question = model.invoke(question_prompt).content.strip()\n",
    "    \n",
    "    answer_prompt = f\"\"\"\n",
    "    Please provide a thoughtful and informative answer to the following question, based on the experiences and insights shared in the Reddit post about Ehlers-Danlos Syndrome (EDS). Use language that is sensitive and respectful to all individuals with EDS, and avoid making direct references to the post's author or any specific individuals mentioned.\n",
    "\n",
    "    When generating the answer, please ensure that the response is formatted as a single, coherent paragraph without any special characters or escape sequences like \"\\\\n\\\\n\". Use only standard characters without any special formatting or encoded characters like slashes (/) or escaped quotes (\\\"). The answer should be easy to read and understand.\n",
    "    \n",
    "    Question: {question}\n",
    "    \n",
    "    Reddit post:\n",
    "    {text_body}\n",
    "    \"\"\"\n",
    "    answer = model.invoke(answer_prompt).content.strip()\n",
    "    \n",
    "    summary = summarize_output(answer)\n",
    "    \n",
    "    return {\"input\": summary, \"instruction\": question, \"output\": answer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_questions_answers(posts):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate questions and answers based on a list of Reddit posts about Ehlers-Danlos Syndrome (EDS).\n",
    "\n",
    "    Args:\n",
    "        posts (list): A list of dictionaries, where each dictionary contains information about a Reddit post, including the post's text body.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of dictionaries, where each dictionary represents a generated question and answer.\n",
    "              Each dictionary has keys \"input\", \"instruction\", and \"output\".\n",
    "              - \"input\" is an empty string.\n",
    "              - \"instruction\" contains the generated question.\n",
    "              - \"output\" contains the generated answer.\n",
    "\n",
    "    The function iterates over each post in the provided list and generates two questions and answers for each post using the `generate_question_answer` function.\n",
    "    The first question is generated without any previous question context, while the second question takes into account the first generated question to ensure that it is different.\n",
    "    The generated questions and answers are stored in the `generated_data` list and returned.\n",
    "    \"\"\"\n",
    "    \n",
    "    generated_data = []\n",
    "    for post in posts:\n",
    "        question1_data = generate_question_answer(post)\n",
    "        generated_data.append(question1_data)\n",
    "        \n",
    "        question2_data = generate_question_answer(post, previous_question=question1_data[\"instruction\"])\n",
    "        generated_data.append(question2_data)\n",
    "    \n",
    "    return generated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_json(data, file_path):\n",
    "    \"\"\"\n",
    "    Save the processed results to a JSON file.\n",
    "    Args:\n",
    "        data (list): The data to save to JSON.\n",
    "        file_path (str): Path to the output JSON file.\n",
    "    \"\"\"\n",
    "    with open(file_path, 'w') as jsonfile:\n",
    "        json.dump(data, jsonfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search Reddit for EDS-related posts\n",
    "posts = search_reddit(query=\"EDS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate questions and answers for each post\n",
    "generated_data = generate_questions_answers(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_results_to_json(generated_data, '../../eds_data/reddit_data/reddit_generated_questions.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "484 out of 242 questions\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(generated_data)} out of {len(posts)} questions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eds",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
