{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f09f137d-6db0-4a47-a67d-7d334dd24b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.extractors import (\n",
    "    SummaryExtractor,\n",
    "    QuestionsAnsweredExtractor,\n",
    "    TitleExtractor,\n",
    "    KeywordExtractor,\n",
    ")\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.core import Settings\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af199494-ca61-4d77-9432-812d871cdc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_doi(doc_):\n",
    "    text = \"\"\n",
    "    for page in doc_:\n",
    "        text += page.get_text()\n",
    "    \n",
    "    match = re.search(r'\\b(10[.][0-9]{4,}(?:[.][0-9]+)*/(?:(?![\"&\\'<>])\\S)+)\\b', text)\n",
    "    \n",
    "    if match:\n",
    "        return match.group()\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73a11536-9d85-46c0-80ec-6c4a8c4314e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data'\n",
    "CREATE_NEW_INDEX = True\n",
    "\n",
    "INDEX_NAME = 'eds-papers'\n",
    "CHUNK_SIZE = 1024\n",
    "LLM_TO_USE = \"gpt-35-turbo\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "681a98ad-cf3d-45cc-9db6-af1a3881c863",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = ['eds_review_paper_Paepe_2012.pdf', 'eds_perspective_paper_2001.pdf']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "252d5e11-c78f-40dd-b1d7-0033e8660f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(os.path.join(os.path.expanduser('~'), '.gpt_config.env'))\n",
    "api_key = os.environ.get('API_KEY')\n",
    "azure_endpoint = os.environ.get('RESOURCE_ENDPOINT')\n",
    "api_version = os.environ.get('API_VERSION')\n",
    "\n",
    "load_dotenv(os.path.join(os.path.expanduser('~'), '.pinecone_config.env'))\n",
    "pinecone_api_key = os.environ.get('PINECONE_API_KEY')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12b66f4d-4df4-4f1b-9682-59a1b72a69b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureOpenAI(\n",
    "    model=LLM_TO_USE,\n",
    "    deployment_name=LLM_TO_USE,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=EMBEDDING_MODEL,\n",
    "    deployment_name=EMBEDDING_MODEL,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "pc = Pinecone(api_key=pinecone_api_key)\n",
    "if CREATE_NEW_INDEX:\n",
    "    pc.create_index(\n",
    "        name=INDEX_NAME,\n",
    "        dimension=len(node_embedding),\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(\n",
    "            cloud='aws', \n",
    "            region='us-east-1'\n",
    "        ) \n",
    "    )\n",
    "pinecone_index = pc.Index(INDEX_NAME)\n",
    "vector_store = PineconeVectorStore(pinecone_index=pinecone_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e4fd26c-87de-4cc0-955d-943d68002595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Processing : File 1/2****\n",
      "Reading the document ...\n",
      "Finding DOI from the document ...\n",
      "Splitting the document into chunks ...\n",
      "Converting each chunk into nodes ...\n",
      "Extracting metadata for each node ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.76it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:10<00:00,  2.21it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:10<00:00,  2.24it/s]\n",
      "100%|███████████████████████████████████████████| 24/24 [00:07<00:00,  3.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for each node and adding DOI of the paper as another metadata ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 24/24 [00:09<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating vectorDB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|█████████████████████████| 24/24 [00:02<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** File 1/2 is completed ****\n",
      "**** Processing : File 2/2****\n",
      "Reading the document ...\n",
      "Finding DOI from the document ...\n",
      "Splitting the document into chunks ...\n",
      "Converting each chunk into nodes ...\n",
      "Extracting metadata for each node ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:01<00:00,  3.34it/s]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:06<00:00,  2.15it/s]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:09<00:00,  1.64it/s]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:04<00:00,  3.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for each node and adding DOI of the paper as another metadata ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [00:06<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating vectorDB ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Upserted vectors: 100%|█████████████████████████| 15/15 [00:00<00:00, 38.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** File 2/2 is completed ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for file_index, file in enumerate(files):\n",
    "    print(f'**** Processing : File {file_index+1}/{len(files)}****')\n",
    "    print('Reading the document ...')\n",
    "    doc = fitz.open(os.path.join(DATA_PATH, file))\n",
    "    \n",
    "    print('Finding DOI from the document ...')\n",
    "    doc_doi = find_doi(doc)\n",
    "    \n",
    "    print('Splitting the document into chunks ...')\n",
    "    text_parser = SentenceSplitter(chunk_size=CHUNK_SIZE)\n",
    "    text_chunks = []\n",
    "    doc_idxs = []\n",
    "    for doc_idx, page in enumerate(doc):\n",
    "        page_text = page.get_text()\n",
    "        cur_text_chunks = text_parser.split_text(page_text)\n",
    "        text_chunks.extend(cur_text_chunks)\n",
    "        doc_idxs.extend([doc_idx]*len(cur_text_chunks))\n",
    "    \n",
    "    print('Converting each chunk into nodes ...')\n",
    "    nodes = []\n",
    "    for idx, text_chunk in enumerate(text_chunks):\n",
    "        node = TextNode(\n",
    "            text=text_chunk,\n",
    "        )\n",
    "        nodes.append(node)\n",
    "    \n",
    "    print('Extracting metadata for each node ...')\n",
    "    extractors = [\n",
    "        TitleExtractor(nodes=5),\n",
    "        QuestionsAnsweredExtractor(questions=3),\n",
    "        SummaryExtractor(summaries=[\"prev\", \"self\"]),\n",
    "        KeywordExtractor(keywords=10)\n",
    "    ]\n",
    "    \n",
    "    pipeline = IngestionPipeline(\n",
    "        transformations=extractors,\n",
    "    )\n",
    "    nodes = await pipeline.arun(nodes=nodes, in_place=False)\n",
    "    \n",
    "    print('Creating embeddings for each node and adding DOI of the paper as another metadata ...')\n",
    "    for node in tqdm(nodes):\n",
    "        node_embedding = embed_model.get_text_embedding(\n",
    "            node.get_content(metadata_mode=\"all\")\n",
    "        )\n",
    "        node.embedding = node_embedding\n",
    "        node.metadata['doi'] = doc_doi\n",
    "        \n",
    "    \n",
    "    print('Populating vectorDB ...')    \n",
    "    vector_store.add(nodes)\n",
    "    print(f'**** File {file_index+1}/{len(files)} is completed ****')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f4f99b-44f7-4bd6-9222-f5887004e9cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
